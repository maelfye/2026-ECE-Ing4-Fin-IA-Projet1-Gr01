# Scoring de crÃ©dit Ã©quitable par optimisation sous contraintes

## 1. Contexte et objectif du projet

Les systÃ¨mes de scoring de crÃ©dit sont aujourd'hui largement automatisÃ©s Ã  l'aide de modÃ¨les de machine learning.
Cependant, ces modÃ¨les peuvent reproduire ou amplifier des biais discriminatoires prÃ©sents dans les donnÃ©es historiques, en dÃ©favorisant certains groupes (par exemple selon le sexe ou la nationalitÃ©).

**L'objectif de ce projet est de :**

Concevoir un systÃ¨me d'intelligence artificielle de scoring de crÃ©dit intÃ©grant explicitement des contraintes d'Ã©quitÃ©, afin de contrÃ´ler et quantifier le compromis entre performance prÃ©dictive et non-discrimination.

â¸»

## 2. ProblÃ©matique Ã©tudiÃ©e

Le projet rÃ©pond Ã  la question suivante :

> Comment intÃ©grer formellement des contraintes d'Ã©quitÃ© dans un modÃ¨le de scoring de crÃ©dit, tout en conservant des performances prÃ©dictives acceptables ?

Pour cela, le problÃ¨me est formulÃ© comme une optimisation sous contraintes, oÃ¹ les mÃ©triques d'Ã©quitÃ© (Demographic Parity, Equalized Odds) sont imposÃ©es directement lors de l'apprentissage du modÃ¨le.

â¸»

## 3. Jeu de donnÃ©es

Le projet utilise un jeu de donnÃ©es clients rÃ©aliste (`clients.csv`) contenant :

### ğŸ”¹ Variable cible
- **default** : dÃ©faut de paiement (0 = non, 1 = oui)

### ğŸ”¹ Attribut sensible
- **sex** : utilisÃ© pour mesurer et contraindre l'Ã©quitÃ© du modÃ¨le

### ğŸ”¹ Variables explicatives
- **DonnÃ©es financiÃ¨res** : income, credit_amount, loan_duration
- **StabilitÃ© professionnelle** : employment_years
- **Situation personnelle** : marital_status, housing_status, dependents
- **Niveau d'Ã©ducation** : education_level

La colonne `name` est supprimÃ©e lors du prÃ©-traitement car elle ne contient aucune information utile pour la prÃ©diction.

â¸»

## 4. Structure du projet

```
FCC/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py           # Configuration (chemins, colonnes)
â”‚   â”œâ”€â”€ preprocessing.py    # PrÃ©-traitement des donnÃ©es
â”‚   â”œâ”€â”€ models.py           # ModÃ¨les ML de base
â”‚   â”œâ”€â”€ fairness.py         # Contraintes d'Ã©quitÃ© (Fairlearn)
â”‚   â”œâ”€â”€ evaluate.py         # MÃ©triques de performance et d'Ã©quitÃ©
â”‚   â”œâ”€â”€ explain.py          # ExplicabilitÃ© (SHAP)
â”‚   â”œâ”€â”€ main.py             # Point d'entrÃ©e du projet
â”‚   â””â”€â”€ plot_results.py     # GÃ©nÃ©ration des graphiques
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/clients.csv
â”‚   â””â”€â”€ processed/results.json
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ documentation_technique.md
â”œâ”€â”€ slides/
â”‚   â””â”€â”€ Scoring de crÃ©dit Ã©quitable par optimisation sous contraintes.pdf
â”œâ”€â”€ notebooks/              # Notebooks d'analyse
â””â”€â”€ requirements.txt
```

â¸»

## 5. Approche mÃ©thodologique

### 5.1 ModÃ¨le de base (baseline)

Un modÃ¨le de rÃ©gression logistique est entraÃ®nÃ© sans contrainte d'Ã©quitÃ©.

**Objectif :**
- Maximiser la performance prÃ©dictive (accuracy, AUC)
- Servir de point de comparaison

Ce modÃ¨le est performant, mais prÃ©sente des diffÃ©rences de traitement entre groupes.

â¸»

### 5.2 Mesure de l'Ã©quitÃ©

Les mÃ©triques suivantes sont utilisÃ©es :
- **Demographic Parity Difference (DP)** : DiffÃ©rence de taux d'acceptation entre groupes
- **Equalized Odds Difference (EO)** : DiffÃ©rence de faux positifs et faux nÃ©gatifs entre groupes

Ces mÃ©triques permettent de quantifier objectivement la discrimination du modÃ¨le.

â¸»

### 5.3 ModÃ¨les Ã©quitables (in-processing)

L'Ã©quitÃ© est intÃ©grÃ©e directement dans l'apprentissage grÃ¢ce Ã  la librairie **Fairlearn**, via l'algorithme :
- **Exponentiated Gradient Reduction**

Deux contraintes sont Ã©tudiÃ©es :
- Demographic Parity
- Equalized Odds

Le paramÃ¨tre `epsilon` contrÃ´le le niveau de tolÃ©rance Ã  la violation de l'Ã©quitÃ©.

â¸»

### 5.4 Analyse du compromis Ã©quitÃ© / performance

Le projet fait varier `epsilon` afin d'observer :
- la rÃ©duction progressive des biais
- l'impact sur la performance prÃ©dictive

Cette analyse permet de montrer que l'Ã©quitÃ© est un choix de gouvernance, et non une propriÃ©tÃ© binaire.

â¸»

## 6. RÃ©sultats principaux

Un fichier [`results.json`](src/data/processed/results.json) est gÃ©nÃ©rÃ© automatiquement et contient :
- performances (accuracy, AUC)
- mÃ©triques d'Ã©quitÃ© (dp_diff, eo_diff)
- mÃ©triques par groupe

### Graphiques produits

**Taux d'acceptation par groupe :**

![Taux d'acceptation par groupe](src/data/processed/selection_rate_by_group.png)

**Trade-off Demographic Parity vs epsilon :**

![Trade-off DP vs epsilon](src/data/processed/tradeoff_dp_vs_eps.png)

### ğŸ” Observation clÃ©
- Le modÃ¨le de base est le plus performant mais le plus discriminant
- Les modÃ¨les Ã©quitables rÃ©duisent fortement les biais
- La perte de performance reste modÃ©rÃ©e et contrÃ´lable

â¸»

## 7. Installation et exÃ©cution

### CrÃ©ation de l'environnement virtuel :
```bash
python3 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate     # Windows
```

### Installation des dÃ©pendances :
```bash
pip install -r FCC/requirements.txt
```

### Lancement du projet :
```bash
python -m FCC.src.main
```

### GÃ©nÃ©ration des graphiques :
```bash
python -m FCC.src.plot_results
```

â¸»

## 8. Tests

Pour exÃ©cuter les tests unitaires :
```bash
pytest FCC/src/tests/
```

â¸»

## ğŸ‘¥ Ã‰quipe
- **Hugo CHRISMANT**
- **Jeremy CLEMENT**
- **Mael FAYE**

Projet rÃ©alisÃ© dans le cadre du cours *Intelligence Artificielle â€“ Finance*
(ECE Paris, IngÃ©nieur 4áµ‰ annÃ©e)
